Hey! Sorry for more updates--fixed a couple bugs. Also, below the code for the mfa function are some commands to test the code step-by-step against the example data in the paper. It is working for me right now, but let me know if anyone has any issues!
-Laura, 11/15

```{r}
#use this vector to scale the data so that the sum of squares for each column is equal to 1. This isn't written into the code but is useful for comparing to the given example.
scaling_vec <- apply(subset(wines, select = unlist(sets)), 2, function(x) sqrt(sum((x - mean(x))^2)))

#helper function for function that separates data into tables and preprocesses
shift_sets <- function(sets) {
  data_start_col <- min(unlist(sets))
  shift <- data_start_col - 1
  new_sets <- lapply(sets, function(x) x - shift)
  return(new_sets)
}

#separate data into individual tables, preprocess and store in a list
#should this list be an object?
data_tables <- function(data, sets, center, scale) {  
  new_sets <- shift_sets(sets)
  tables <- list()
  for(i in 1:length(sets)) {
    table <- subset(data, select = sets[[i]])
    if(class(scale) == "logical") {
      scaling_vec <- scale
    } else {
      scaling_vec <- scale[new_sets[[i]]]
    }
    tables[[i]] <- scale(table, center = center, scale = scaling_vec)
  }
  return(tables)
}  

#determine the weights for each individual table
#should this be a method?
weights <- function(list) {
  #create a nested list with the svd matrices for each data table
  svd_list <- lapply(list, svd)
  #create vector of weights
  weights <- vector()
  for(i in 1:length(list)) {
    #extract first singular value from diagonal matrix produced in SVD
    val <- svd_list[[i]]$d[1]
    #calculate weight from singular value
    weights[i] <- 1/val^2
  }
  return(weights)
}  

#create matrix of weightings
weighting_matrix <- function(weights, sets) {
  weight_vec <- vector()
  for(i in 1:length(sets)) {
    weight_vec <- c(weight_vec, rep(weights[i], length(sets[[i]])))
  }
  A <- diag(weight_vec)
  return(A)
}

#MFA as simple PCA
#should this also be a method?
pca_func <- function(list, sets) {
#input is list of data tables
  new_sets <- shift_sets(sets)
  weights <- weights(list)
  A <- weighting_matrix(weights, sets)
  #combine data tables into one big matrix
  x_tilde <- matrix(unlist(list), nrow(list[[1]])) %*% A^(1/2)
  x_svd <- svd(x_tilde)
  eigen_values <- sqrt(1/nrow(list[[1]])) * x_svd$d

  #calculate list of partial loadings
  negative_root_weights <- weights ^ (-1/2)
  negative_root_A <- weighting_matrix(negative_root_weights, sets)
  q <- t(t(x_svd$v) %*% negative_root_A)
  partial_loadings <- list()
  for(i in 1:length(sets)) {
    partial_loadings[[i]] <- t(subset(t(q), select = new_sets[[i]]))
  }

  #list of partial factor scores
  F_partial <- list()
  for(i in 1:length(list)) {
    F_partial[[i]] <- length(list) * weights[i] * list[[i]] %*% partial_loadings[[i]]
  }

  #save results we want in a list (we don't really need all of these but it is useful to have them while we test these functions against the example)
  out <- list(
    weightings_matrix = A,
    simple_pca = x_svd,
    eigen_values = eigen_values,
    loadings = q,
    partial_loadings = partial_loadings,
    partial_factor_scores = F_partial
  )
  out
}

#constructor function
make_mfa <- function(pca) {
  res <- list(
    eigen_values = pca$eigen_values, #vector
    common_factor_scores = pca$simple_pca$u %*% diag(pca$simple_pca$d), #matrix
    partial_factor_scores = pca$partial_factor_scores, #list
    loadings = pca$loadings
  )
  class(res) <- "mfa"
  res
}

mfa <- function(data, sets, ncomps = NULL, center = TRUE, scale = TRUE) {
#data can be matrix or data frame
#sets is a list of vectors indicating sets/blocks of variables, can be character vectors with names or numeric vectors with position of variables in the data table
#ncomps is an integer indicating how many components/factors are to be extracted, NULL indicates all components
#center can be logical value or numeric vector of length equal to number of active variables; if numeric vector, each variable has corresponding value subtracted from it; if TRUE, subtract column means
#scale can be logical value or numeric vector of length equal to number of active variables
#return vector of eigenvalues, matrix of common factor scores, matrix of partial factor scores, matrix of loadings
  tables <- data_tables(data, sets, center, scale)
  pca <- pca_func(tables, sets)
  make_mfa(pca)
}
```


```{r}
#customize to your working directory
wines <- read.csv("/Users/laurakatz/stat243/wines.csv", stringsAsFactors = FALSE)
sets <- list(2:7, 8:13, 14:19, 20:24, 25:30, 31:35, 36:39, 40:45, 46:50, 51:54)

scaling_vec <- apply(subset(wines, select = unlist(sets)), 2, function(x) sqrt(sum((x - mean(x))^2)))
tables <- data_tables(wines, sets, TRUE, scaling_vec)
round(tables[[1]], 2) #compare this output to (54) in the paper
weights <- weights(tables)
weights #compare to (61) in the paper
results <- pca_func(tables, sets)
round(results$eigen_values, 3) #compare to table 2 in the paper
round(results$partial_factor_scores[[1]], 3) #compare first 2 columns to (66) in the paper
```


